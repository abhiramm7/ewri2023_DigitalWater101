{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10303621",
   "metadata": {},
   "source": [
    "# Data Filtering\n",
    "\n",
    "#### Objective ü•Ö\n",
    "\n",
    "Data in the real world is far from perfect. This notebook exposes the workshop participants to a workflow for filtering sensor data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41206522",
   "metadata": {},
   "source": [
    "### Scenario Epsilon\n",
    "\n",
    "In this notebook, we will use a combined stormwater network with eleven controllable assets as our case study. The orange nodes in the image below represent these controllable assets.\n",
    "\n",
    "![epsilon](./data/epsilon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea79a4b",
   "metadata": {},
   "source": [
    "**Problem Statement**\n",
    "\n",
    "We have recorded measured data from all eleven controllable locations during consecutive storm events, and we want to estimate the storage utilization in the network.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b934f",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Load, visuvalize, and figure out what is hiding in the data üîç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We will be relying on pandas a lot to help us deal with timeseries data\n",
    "# if you haven't used pandas before, we cannot recommend it enough! \n",
    "# We ‚ù§Ô∏è üêº\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RC parms for pretty plots üíÅüèΩ\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.style.use('seaborn-v0_8-dark-palette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the measured data\n",
    "measured_data = pd.read_csv(\"./data/measured_data_epsilon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b75f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a64be8",
   "metadata": {},
   "source": [
    "Each column represents the depth measurement data in **ft** in the storage asset represented by the orange nodes in the above figure. The column <code>Unnamed: 0</code> represents the time of the measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d981a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us set the timestamp as the index of the index\n",
    "# index will help us better query depth data\n",
    "measured_data = measured_data.set_index(\"Unnamed: 0\")\n",
    "# convert index to datetime object\n",
    "measured_data.index = pd.to_datetime(measured_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=125)\n",
    "plt.plot(measured_data['004'])\n",
    "plt.title(\"Depth in 004\")\n",
    "plt.ylabel(\"Depth (ft)\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "# Rotate axis so that they are readable\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelrotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0573675e",
   "metadata": {},
   "source": [
    "Something is going on. Clearly, depth cannot be negative. Furthermore, it cannot rapidly go from 3 to 20. So we need to remove anomalies. But let us zoom into it to see if there is something else going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom and enhance\n",
    "# Let us take a look at the diurnal patters to see if need to handle anything else\n",
    "depth_4 = measured_data['004'].loc[pd.Timestamp(\"2017-01-12\"):pd.Timestamp(\"2017-01-14\")]\n",
    "\n",
    "plt.figure(figsize=(20, 5), dpi=100)\n",
    "plt.plot(depth_4)\n",
    "plt.ylabel(\"Depth (ft)\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "# Rotate axis so that they are readable\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelrotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294729da",
   "metadata": {},
   "source": [
    "That does not look like a diurnal pattern. However, if you squint, it does look like a signal is hiding amongst the noise. Furthermore, it seems there are some gaps in the data as well. Let us take a look to see how these gaps are represented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_data['004'].loc[pd.Timestamp(\"2017-01-06\"):pd.Timestamp(\"2017-01-07\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d2f11",
   "metadata": {},
   "source": [
    "Looks like there are some NaNs hiding in the data as well. There are a lot types of NaNs in Python üò≠, pandas has <code>dronna()</code> function which will solve all our problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9b609",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "1. There are outliers in the depth data that have be removed.\n",
    "2. There is measurement noise in the data.\n",
    "3. There are NaNs in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc834d1",
   "metadata": {},
   "source": [
    "üèãüèΩ **Exercise 1.1**\n",
    "\n",
    "Explore the data to see if there is anything else hiding?\n",
    "\n",
    "üòâ Hint 1 -> Take a look at site 006 \n",
    "\n",
    "üòâ Hint 2 -> Gradient can be computed using <code>measured_data['004'].diff()<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying data for for a particular site\n",
    "measured_data['006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate gradient\n",
    "measured_data['004'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a9ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gradients to figure the hiding anamoly\n",
    "# < Your amesome code goes here >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f5c91",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Based on the issues identified in Exercise-1, clean the data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b51c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_4 = measured_data['004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13aeba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us remove NaN values first\n",
    "depth_4 = depth_4.dropna()\n",
    "# Let us clear off the negative values next\n",
    "depth_4 = depth_4[depth_4 > 0.0]\n",
    "# Remove the flat lines\n",
    "# 1. gradient of 0.0 means flatline\n",
    "gradient = depth_4.diff()\n",
    "# 2. identify the timesteps when gradients are 0\n",
    "index_flatlines = depth_4[depth_4.diff() == 0.0].index\n",
    "# 3. remove these values\n",
    "depth_4 = depth_4.drop(index_flatlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5115a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=125)\n",
    "plt.plot(depth_4)\n",
    "plt.title(\"Depth in 004\")\n",
    "plt.ylabel(\"Depth (ft)\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "# Rotate axis so that they are readable\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelrotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3fe6a",
   "metadata": {},
   "source": [
    "Now to the fun stuff! Let's remove the anomalies from the data. Thankfully, they look obvious; let us try something simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42286b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. remove the anamolies\n",
    "mean = depth_4.mean()\n",
    "std = depth_4.std()\n",
    "# Let remove everything that exceeds 95% CI\n",
    "upper_limit = mean + 2 * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_4[depth_4 > upper_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6699fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_limit_excess = depth_4[depth_4 > upper_limit].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae94f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_4 = depth_4.drop(up_limit_excess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669de518",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=125)\n",
    "plt.plot(depth_4)\n",
    "plt.title(\"Depth in 004\")\n",
    "plt.ylabel(\"Depth (ft)\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "# Rotate axis so that they are readable\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelrotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d7ea8",
   "metadata": {},
   "source": [
    "üèãüèΩ **Exercise 2.1**\n",
    "\n",
    "Using the above code, clean the data for rest of the sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d28077",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_depth_data = pd.DataFrame()\n",
    "\n",
    "for site in measured_data.columns:\n",
    "    # Isolate the data for a site \n",
    "    depth_site = measured_data[site]\n",
    "    \n",
    "    # Let us remove NaN values first\n",
    "\n",
    "    \n",
    "    # Let us clear off the negative values next\n",
    "\n",
    "    \n",
    "    # Remove the flat lines\n",
    "    # 1. gradient of 0.0 means flatline\n",
    "\n",
    "    # 2. identify the timesteps when gradients are 0\n",
    "\n",
    "    # 3. remove these values\n",
    "\n",
    "    \n",
    "    \n",
    "    # 4. remove the anamolies\n",
    "\n",
    "    # Let remove everything that exceeds 95% CI\n",
    "\n",
    "    # Note: concat function helps stack the cleaned data into columns\n",
    "    # We assume depth_site is the name of the cleaned data \n",
    "    # This is equivalent to the depth_4 above.\n",
    "    cleaned_depth_data = pd.concat([cleaned_depth_data, depth_site], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673522a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b6652a",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Now that we have cleaned the apparent stuff, how do we clean the measurement noise that is obfuscating our data? Let us take some help from my favorite Frenchman, Joseph Fourier\n",
    "\n",
    "![Fourier](https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Fourier2_-_restoration1.jpg/440px-Fourier2_-_restoration1.jpg)\n",
    "\n",
    "We will use a 200 year old method to help us extract our signal.\n",
    "[Denoising Data using FFT](https://www.youtube.com/watch?v=s2K1JfNR7Sc) provides a really good overview of the fourier filtering approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_filtering(signal, t, dt, psd_threshold):\n",
    "    n = len(t)\n",
    "    # Compute the FFT\n",
    "    fhat = np.fft.fft(signal,n)\n",
    "    # Power spectrum (power per freq)\n",
    "    PSD = fhat * np.conj(fhat) / n\n",
    "     # Create x-axis of frequencies in Hz\n",
    "    freq = (1/(dt*n)) * np.arange(n)\n",
    "    # Only plot the first half of freqs\n",
    "    L = np.arange(1, np.floor(n/2),dtype='int')\n",
    "    # Find all freqs with large power\n",
    "    indices = PSD > psd_threshold\n",
    "    # Zero out all others\n",
    "    PSDclean = PSD * indices\n",
    "    # Zero out small Fourier coeffs. in Y\n",
    "    fhat = indices * fhat\n",
    "    # Inverse FFT for filtered time signal\n",
    "    ffilt = np.fft.ifft(fhat)\n",
    "    return freq, PSD, ffilt, L, PSDclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94210f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(data: pd.DataFrame, psd_threshold: float, plot: bool):\n",
    "    # convert datetime index to seconds starting from 0\n",
    "    column_name = data.columns[0]\n",
    "    depth_site = data[[column_name]]\n",
    "    depth_site = depth_site.resample(\"15min\").mean().interpolate()\n",
    "    depth_site['time'] = depth_site.index.values\n",
    "    depth_site['time'] = (depth_site['time'] - depth_site['time'][0]).apply(lambda x: x.total_seconds())\n",
    "    \n",
    "    # Note: 1/900 as each timestep is 15min = 900s econds\n",
    "    freq, PSD, ffilt, L, PSDclean = fourier_filtering(signal=depth_site[column_name].values,\n",
    "                                                      t=depth_site['time'].values,\n",
    "                                                      dt=1/900.0,\n",
    "                                                      psd_threshold=psd_threshold)\n",
    "    \n",
    "    # Ignore the imaginary numbers, they are just in my head\n",
    "    ffilt = ffilt.real\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(20, 10), dpi=125)\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(depth_site.index, depth_site[column_name].values, label='Noisy', alpha=0.5)\n",
    "        plt.plot(depth_site.index, ffilt,color='b',label='Filtered', linewidth=2.0)\n",
    "        plt.ylabel(\"Depth (ft)\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(freq[L],PSD[L],label='Noisy', alpha=0.9)\n",
    "        plt.plot(freq[L],PSDclean[L],label='Filtered', linewidth=2.0)\n",
    "        plt.xlim(freq[L[0]], 20)\n",
    "        plt.xlabel(\"Frequency (Hz)\")\n",
    "        plt.ylabel(\"PSD\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.suptitle(f\"{column_name} Filtered\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        return pd.DataFrame(data={column_name:ffilt}, index=depth_site.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns(data=depth_4.to_frame(), psd_threshold=1.0, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b73269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the plot to false we can get the cleaned data\n",
    "filter_columns(data=depth_4.to_frame(), psd_threshold=1.0, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed30ea5",
   "metadata": {},
   "source": [
    "üèãüèΩ **Exercise 3.1**\n",
    "\n",
    "Using the above code generate clean data. There isn't one correct answer. You, as an engineer, will have to make a call on what is good enough for our goal of estimating the degree of utilization of the storage assets.\n",
    "\n",
    "üßê : Do we have to identify a new filtering threshold (<code>psd_threshold</code>) for each site, or can we use the same threshold for all the sensors?\n",
    "    \n",
    "ü§î : Can we use fourier filtering and avoid writing code to deal with flatlines and anomalies?\n",
    "    \n",
    "Note: Make sure you completed Exercise 2.1 and are using the <code>cleaned_depth_data</code> for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0614e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_data = pd.DataFrame()\n",
    "\n",
    "# TODO: figure out the right threshold for filtering data\n",
    "# This is the üéöÔ∏è knob you would want to dial \n",
    "psd_threshold_site = 0.0\n",
    "\n",
    "for site in cleaned_depth_data.columns:\n",
    "    # Isolate the data for a site \n",
    "    depth_site = cleaned_depth_data[[site]]\n",
    "    \n",
    "    # FFT!! ü™Ñ\n",
    "    depth_site = filter_columns(data=depth_site, psd_threshold=psd_threshold_site, plot=False)\n",
    "\n",
    "    # concat data into a common DataFrame\n",
    "    denoised_data = pd.concat([denoised_data, depth_site], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7b486",
   "metadata": {},
   "source": [
    "üèãüèΩ **Exercise 3.2**\n",
    "\n",
    "Once we have the clean data, now let us compute the average utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_depth = denoised_data.mean(axis=0).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = {\"004\": 14.7, \n",
    "             \"006\": 9,\n",
    "             \"011\": 14,\n",
    "             \"022\": 15.5,\n",
    "             \"027\": 15.5,\n",
    "             \"030\": 15.5,\n",
    "             \"033\": 15.5,\n",
    "             \"039\": 12.25,\n",
    "             \"044\": 15.5,\n",
    "             \"050\": 10.5,\n",
    "             \"060\": 11.5\n",
    "            }\n",
    "utilization = {}\n",
    "\n",
    "for site in average_depth.keys():\n",
    "    utilization[site] = average_depth[site]/max_depth[site]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1db87",
   "metadata": {},
   "source": [
    "Based on the above data, make a decision on the available capacity in the system.\n",
    "\n",
    "ü§®: Is there any capacity in the system that we can levearge to improve the operation of the stormwater network?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
